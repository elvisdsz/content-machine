{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf1f6f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True)\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed977701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    api_key=GOOGLE_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "233c6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class Router(BaseModel):\n",
    "    \"\"\"Decide the next agent to route to\"\"\"\n",
    "    next_agent: Literal[\"weather\", \"flights\", \"__end__\"]\n",
    "\n",
    "supervisor_model = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c185016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langgraph.types import Command\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Supervisor Agent\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command:\n",
    "    \"\"\"The central supervisor agent that routes to the correct agent or ends the conversation.\"\"\"\n",
    "    print(\"==[ Supervisor ]==\")\n",
    "\n",
    "    sys_prompt = \"\"\"You are a supervisor agent routing tasks to a specialist agent.\n",
    "    Based on the user's request, choose the appropriate agent only from the followin list.\n",
    "\n",
    "    Available agent:\n",
    "    - Weather: For questions about weather forecasts.\n",
    "    - Flights: For questions about flight information.\n",
    "\n",
    "    If the user says thank you or the conversation is over, choose '__end__'.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", sys_prompt),\n",
    "            (\"user\", user_prompt)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if isinstance(state['messages'][-1], HumanMessage):\n",
    "        response = supervisor_model.invoke(prompt.format_messages())\n",
    "        print(f\"Supervisor routing to: {response.next_agent}\")\n",
    "        return Command(goto=response.next_agent.lower())\n",
    "    else:\n",
    "        return Command(goto='__end__')\n",
    "    \n",
    "\n",
    "# Specialist Agents\n",
    "\n",
    "def weather_agent(state: MessagesState) -> Command:\n",
    "    \"\"\"A specialist agents for handling weather related queries\"\"\"\n",
    "    print(\"*==[ Weather Agent ]==*\")\n",
    "    sys_prompt = \"You are a weather forecaster. Provide a concise mock weather forecast for the location mentioned in the user's message.\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", sys_prompt),\n",
    "        (\"user\", state[\"messages\"][-1].content)\n",
    "    ])\n",
    "    response = llm.invoke(prompt.format_messages())\n",
    "    print(f\"Response: {response.content}\")\n",
    "    # Return to the supervisor after run\n",
    "    return Command(\n",
    "        goto=\"supervisor\",\n",
    "        update={\"messages\": [response]}\n",
    "    )\n",
    "\n",
    "def flights_agent(state: MessagesState) -> Command:\n",
    "    \"\"\"A specialist agents for handling flight status-related queries\"\"\"\n",
    "    print(\"*==[ Flight Agent ]==*\")\n",
    "    sys_prompt = \"You are a flight information assistant. Provide some mock flight details for the destination in the user's message. Respond with short concise information.\"\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", sys_prompt),\n",
    "        (\"user\", state[\"messages\"][-1].content)\n",
    "    ])\n",
    "    response = llm.invoke(prompt.format_messages())\n",
    "    print(f\"Response: {response.content}\")\n",
    "    # Return to the supervisor after run\n",
    "    return Command(\n",
    "        goto=\"supervisor\",\n",
    "        update={\"messages\": [response]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97dbc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"supervisor\", supervisor)\n",
    "workflow.add_node(\"weather\", weather_agent)\n",
    "workflow.add_node(\"flights\", flights_agent)\n",
    "\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Compile graph\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7cb1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==[ Supervisor ]==\n",
      "Supervisor routing to: weather\n",
      "*==[ Weather Agent ]==*\n",
      "Supervisor routing to: weather\n",
      "*==[ Weather Agent ]==*\n",
      "Response: Good morning, Maldives! Get ready for a beautiful day across the islands. Expect **sunny skies** with a gentle breeze. Temperatures will be comfortably warm, topping out around **30 degrees Celsius (86 degrees Fahrenheit)**. There's a **very low chance of a brief, isolated shower** this afternoon, but overall, it's a perfect day for enjoying the beaches and turquoise waters.\n",
      "==[ Supervisor ]==\n",
      "Response: Good morning, Maldives! Get ready for a beautiful day across the islands. Expect **sunny skies** with a gentle breeze. Temperatures will be comfortably warm, topping out around **30 degrees Celsius (86 degrees Fahrenheit)**. There's a **very low chance of a brief, isolated shower** this afternoon, but overall, it's a perfect day for enjoying the beaches and turquoise waters.\n",
      "==[ Supervisor ]==\n",
      "==[ Supervisor ]==\n",
      "==[ Supervisor ]==\n",
      "Supervisor routing to: flights\n",
      "*==[ Flight Agent ]==*\n",
      "Supervisor routing to: flights\n",
      "*==[ Flight Agent ]==*\n",
      "Response: **Flights to London from Manchester:**\n",
      "\n",
      "*   **Airline:** British Airways\n",
      "*   **Flight Number:** BA1345\n",
      "*   **Departure:** MAN 10:00 AM\n",
      "*   **Arrival:** LHR 11:15 AM\n",
      "*   **Duration:** 1h 15m\n",
      "==[ Supervisor ]==\n",
      "Response: **Flights to London from Manchester:**\n",
      "\n",
      "*   **Airline:** British Airways\n",
      "*   **Flight Number:** BA1345\n",
      "*   **Departure:** MAN 10:00 AM\n",
      "*   **Arrival:** LHR 11:15 AM\n",
      "*   **Duration:** 1h 15m\n",
      "==[ Supervisor ]==\n",
      "==[ Supervisor ]==\n",
      "==[ Supervisor ]==\n",
      "Supervisor routing to: __end__\n",
      "Supervisor routing to: __end__\n",
      "Goodbye!\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    # graph.stream() invokes the graph and streams the result\n",
    "    events = graph.stream({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    for event in events:\n",
    "        # Only print AI's response here\n",
    "        if \"messages\" in event:\n",
    "            event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
